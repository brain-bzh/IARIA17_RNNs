{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import reber as reb\n",
    "import RNNv\n",
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Reber's\n",
    "This notebook reproduce the experiment presented in *link* (part III).\n",
    "## Reber's grammar\n",
    "The following code present how to use the reber module.     \n",
    "It produces Reber's strings and transforms them into basis vectors' sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPVPXTTTTVVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
       " array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.]),\n",
       " array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = reb.get_reber()\n",
    "print(r)\n",
    "reb.reber_to_seq(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset's generation\n",
    "We generate a dataset in the classical ways for reccurent nets,   \n",
    "an example of the dataset is constitutes by two sequences.   \n",
    "The goal is to predict the ith entry of the second sequence when the net   \n",
    "is given the ith entry of the first one.    \n",
    "We print dataset[0] to give an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BPVPSE',\n",
       " [array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
       "  array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.])],\n",
       " [array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
       "  array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_SIZE = 256\n",
    "dataset = []\n",
    "for d in range(DATASET_SIZE):\n",
    "    reber_str = reb.get_reber()\n",
    "    dataset.append((reber_str, reb.reber_to_seq(reber_str)[:-1], reb.reber_to_seq(reber_str)[1:]))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNNs\n",
    "## Model Definition\n",
    "We construct a Vanilla RNN with Theano.   \n",
    "Same setting as in the paper: 5 hidden units.   \n",
    "The Reber's alphabet is of size 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.341328448716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '23643' (I am process '23844')\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 5\n",
    "rnn = RNNv.RNNv(7,n_hidden,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "We apply a simple training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: error of 3.312931, lr of 0.050000\n",
      "Iteration 100: error of 3.098041, lr of 0.025000\n",
      "Iteration 200: error of 3.096029, lr of 0.025000\n",
      "Iteration 300: error of 3.094813, lr of 0.025000\n",
      "Iteration 400: error of 3.093686, lr of 0.025000\n",
      "Iteration 500: error of 3.092555, lr of 0.025000\n",
      "Iteration 600: error of 3.091407, lr of 0.025000\n",
      "Iteration 700: error of 3.090157, lr of 0.025000\n",
      "Iteration 800: error of 3.088565, lr of 0.025000\n",
      "Iteration 900: error of 3.086588, lr of 0.025000\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "lr = 0.05\n",
    "\n",
    "epsilon = 1e-5\n",
    "\n",
    "h0 = np.zeros(n_hidden)\n",
    "\n",
    "last_err = 0.0\n",
    "for i in range(n_epochs):\n",
    "    dataset_err = []\n",
    "    for d in dataset:\n",
    "        dataset_err.append(rnn.train_step(h0,d[1],d[2],lr)[2])\n",
    "    \n",
    "    mean_err = np.mean(dataset_err)\n",
    "    \n",
    "    if i != 0 and last_err - mean_err < 0:\n",
    "        lr /= 2\n",
    "    \n",
    "    if i%(n_epochs/10) == 0:\n",
    "        print \"Iteration %d: error of %f, lr of %f\" % (i, mean_err, lr)\n",
    "    \n",
    "    if abs(last_err-mean_err) < epsilon:\n",
    "        print \"Early stopping, iteration %d: error of %f, lr of %f\" % (i, mean_err, lr)\n",
    "        break\n",
    "    \n",
    "    last_err = mean_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results\n",
    "### Plotting routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reber_heatmap(to_show,hidden_layer=True):\n",
    "    labels = ['B', 'T', 'S', 'X', 'V', 'P', 'E']\n",
    "\n",
    "\n",
    "    the_map = []\n",
    "    for s in to_show:\n",
    "        seq = reb.reber_to_seq(s)\n",
    "        data = rnn.model(seq,h0)[int(hidden_layer)][-1]\n",
    "        the_map.append(data[-1])\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(the_map, interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels(['']+labels)\n",
    "ax.set_yticklabels([''])\n",
    "plt.yticks(range(0,len(to_show)),to_show)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
